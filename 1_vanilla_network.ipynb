{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1727,
   "id": "ac212bfe-98f4-4211-954e-b9197e1fc613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 10000 12000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import fastbook\n",
    "# from fastai.vision.all import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch import tensor\n",
    "from torch.utils.data import DataLoader\n",
    "fastbook.setup_book()     \n",
    "\n",
    "\n",
    "def one_hot(digit):\n",
    "    return tensor([float(i == digit) for i in range(10)]).unsqueeze(1)\n",
    "\n",
    "\n",
    "pic_to_matrix = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])\n",
    "matrix_to_column = transforms.Compose([\n",
    "    transforms.Lambda(torch.flatten),\n",
    "    transforms.Lambda(lambda x: x.unsqueeze(1)),\n",
    "])\n",
    "pic_to_column = transforms.Compose([\n",
    "    pic_to_matrix,\n",
    "    matrix_to_column,\n",
    "])\n",
    "\n",
    "\n",
    "def to_pic(pixels):\n",
    "    digit = pixels.numpy().reshape(28,28)\n",
    "    digit = digit.astype(np.uint8)\n",
    "    return Image.fromarray(digit).resize((100, 100))\n",
    "\n",
    "\n",
    "path = fastbook.untar_data(fastbook.URLs.MNIST)\n",
    "\n",
    "\n",
    "def pic_loader(pic_transform, label_transform=None):\n",
    "    def loader(path):\n",
    "        return torchvision.datasets.ImageFolder(\n",
    "            path.as_posix(),\n",
    "            transform=pic_transform,\n",
    "            target_transform=label_transform, \n",
    "        )\n",
    "    return loader\n",
    "\n",
    "\n",
    "def load_mnist(loader, train_proportion=0.8):\n",
    "    full_dataset = loader(path / \"training\")\n",
    "    \n",
    "    \n",
    "    train_size = int(train_proportion * len(full_dataset))\n",
    "    valid_size = len(full_dataset) - train_size\n",
    "    training_set, validation_set = torch.utils.data.random_split(full_dataset, [train_size, valid_size])\n",
    "\n",
    "    # Dataset using the \"testing\" folder\n",
    "    testing_set = loader(path / \"testing\")\n",
    "    \n",
    "    return training_set, testing_set, validation_set\n",
    "\n",
    "\n",
    "loader = pic_loader(pic_transform=pic_to_column, label_transform=one_hot)\n",
    "training_set, testing_set, validation_set = load_mnist(loader, train_proportion=0.8)\n",
    "print(len(training_set), len(testing_set), len(validation_set))\n",
    "\n",
    "training_set = DataLoader(training_set, batch_size=30, shuffle=True)\n",
    "testing_set = DataLoader(testing_set, batch_size=30, shuffle=True)\n",
    "validation_set = DataLoader(validation_set, batch_size=30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1713,
   "id": "11ef64f0-7981-4fd7-869e-2903a9d77a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def graph_updater():\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1) \n",
    "\n",
    "    def add_datapoint(y):\n",
    "        xs, ys = [], []\n",
    "        if ax.lines:\n",
    "            xs = ax.lines[0].get_xdata()\n",
    "            ys = ax.lines[0].get_ydata()\n",
    "\n",
    "        prev_x = xs[-1] if len(xs) > 0 else 0        \n",
    "\n",
    "        ax.cla()\n",
    "        ax.plot(np.append(xs, prev_x + 1), np.append(ys, y))\n",
    "        \n",
    "        #ax.set_xlim(0, prev_x + 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        \n",
    "        display(fig)\n",
    "\n",
    "        clear_output(wait = True)\n",
    "    \n",
    "    return add_datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1707,
   "id": "cc7bf7b2-9df7-48ae-bea8-27948128adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct(expected, output):\n",
    "    return int(torch.argmax(expected) == torch.argmax(output))\n",
    "       \n",
    "\n",
    "def cost(expected, output):\n",
    "    return torch.sum((expected - output)**2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1708,
   "id": "56a6571d-afca-4811-90c8-7fe7212d9587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_layer_grads(grads):\n",
    "    return [torch.stack(i).mean(0) for i in zip(*grads)]\n",
    "    \n",
    "\n",
    "def merge_grads(grads):\n",
    "    return [merge_layer_grads(l) for l in zip(*grads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1705,
   "id": "9c566f3a-ca52-4386-a55c-cf29e23e96cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2(a, b):\n",
    "    return torch.sum((a - b)**2) / 2\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, layers, lr=0.001, nonlinearity=torch.nn.Sigmoid(), deriv=lambda x: x * (1 - x), cost_func=l2):\n",
    "        self.activation = nonlinearity\n",
    "        self.deriv = deriv\n",
    "        self.cost_func = cost_func\n",
    "        self.lr = lr\n",
    "        self.w = [torch.rand(n_out, n_in) / torch.sqrt(tensor(n_in)) for n_in, n_out in zip(layers, layers[1:])]\n",
    "        self.b = [torch.rand(n_out, 1) for n_out in layers[1:]]\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        a = inputs\n",
    "        activations = [a]\n",
    "        for w, b in zip(self.w, self.b):\n",
    "            a = self.activation(w @ a + b)\n",
    "            activations.append(a)\n",
    "        return activations\n",
    "         \n",
    "    def step(self, inputs):\n",
    "        return self.forward(inputs)[-1]\n",
    "    \n",
    "    def gradient(self, activations, expected):\n",
    "        layer_gradients = []\n",
    "       \n",
    "        in_ = activations[-2]\n",
    "        out = activations[-1]\n",
    "\n",
    "        nabla_C = out - expected\n",
    "        sigma_L = self.deriv(out)\n",
    "        delta_L = nabla_C * self.deriv(out)\n",
    "\n",
    "        prev_delta = delta_L\n",
    "        \n",
    "        dw = prev_delta @ torch.transpose(in_, 0, 1) \n",
    "        db = prev_delta \n",
    "        layer_gradients.append([dw, db])\n",
    "        \n",
    "        for l in range(len(self.w) - 2, -1, -1):\n",
    "            in_ = activations[l]\n",
    "            out = activations[l+1]\n",
    "            \n",
    "            delta_l = (torch.transpose(self.w[l+1], 0, 1) @ prev_delta) * self.deriv(out)\n",
    "            prev_delta = delta_l\n",
    "            \n",
    "            dw = delta_l @ torch.transpose(in_, 0, 1)\n",
    "            db = delta_l\n",
    "            \n",
    "            layer_gradients.append([dw, db])\n",
    "        \n",
    "        return list(reversed(layer_gradients))\n",
    "    \n",
    "    def update(self, gradient, lr):\n",
    "        for i, (w, b) in enumerate(gradient):\n",
    "            self.w[i] -= lr * w\n",
    "            self.b[i] -= lr * b\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1737,
   "id": "221de779-4e9d-46a6-a6f5-ac521f3d8848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(network, dataset, lr):\n",
    "    accuracy = []\n",
    "    costs = []\n",
    "    \n",
    "    for batch in iter(dataset):\n",
    "        grads = []\n",
    "        for xs, expected in zip(*batch):\n",
    "            activations = network.forward(xs)\n",
    "            output = activations[-1]\n",
    "            grad = network.gradient(activations, expected)\n",
    "            grads.append(grad)\n",
    "            accuracy.append(is_correct(expected, output))\n",
    "            costs.append(cost(expected, output))\n",
    "         \n",
    "        grad = merge_grads(grads)\n",
    "        network.update(grad, lr)\n",
    "\n",
    "    return tensor(accuracy).float().mean(), torch.stack(costs).mean()\n",
    "\n",
    "\n",
    "def train(network, dataset, epochs, lr, show_progress=True):\n",
    "    if show_progress:\n",
    "        add_datapoint = graph_updater()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = datetime.now()\n",
    "        \n",
    "        avg_accuracy, avg_cost = run_epoch(network, dataset, lr)\n",
    "        \n",
    "        if show_progress and (not epoch % 1):\n",
    "            print(f'epoch {epoch}: accuracy={round(avg_accuracy.item(), 3)}, cost={round(avg_cost.item(), 3)}, time: {datetime.now() - start}')\n",
    "            add_datapoint(avg_accuracy)\n",
    "    \n",
    "    return avg_accuracy, avg_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1738,
   "id": "2485578e-c56f-4263-b90d-da629ccb9440",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Network((28*28, 50, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1740,
   "id": "f77eb00b-a945-489f-a4a9-d17627ffee90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8986), tensor(0.0799))"
      ]
     },
     "execution_count": 1740,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(n, training_set, 5, lr=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d381a6a-ce92-49cd-8b86-f41eaf796dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
