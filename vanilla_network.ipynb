{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1727,
   "id": "ac212bfe-98f4-4211-954e-b9197e1fc613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 10000 12000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import fastbook\n",
    "# from fastai.vision.all import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch import tensor\n",
    "from torch.utils.data import DataLoader\n",
    "fastbook.setup_book()     \n",
    "\n",
    "\n",
    "def one_hot(digit):\n",
    "    return tensor([float(i == digit) for i in range(10)]).unsqueeze(1)\n",
    "\n",
    "\n",
    "pic_to_matrix = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])\n",
    "matrix_to_column = transforms.Compose([\n",
    "    transforms.Lambda(torch.flatten),\n",
    "    transforms.Lambda(lambda x: x.unsqueeze(1)),\n",
    "])\n",
    "pic_to_column = transforms.Compose([\n",
    "    pic_to_matrix,\n",
    "    matrix_to_column,\n",
    "])\n",
    "\n",
    "\n",
    "def to_pic(pixels):\n",
    "    digit = pixels.numpy().reshape(28,28)\n",
    "    digit = digit.astype(np.uint8)\n",
    "    return Image.fromarray(digit).resize((100, 100))\n",
    "\n",
    "\n",
    "path = fastbook.untar_data(fastbook.URLs.MNIST)\n",
    "\n",
    "\n",
    "def pic_loader(pic_transform, label_transform=None):\n",
    "    def loader(path):\n",
    "        return torchvision.datasets.ImageFolder(\n",
    "            path.as_posix(),\n",
    "            transform=pic_transform,\n",
    "            target_transform=label_transform, \n",
    "        )\n",
    "    return loader\n",
    "\n",
    "\n",
    "def load_mnist(loader, train_proportion=0.8):\n",
    "    full_dataset = loader(path / \"training\")\n",
    "    \n",
    "    \n",
    "    train_size = int(train_proportion * len(full_dataset))\n",
    "    valid_size = len(full_dataset) - train_size\n",
    "    training_set, validation_set = torch.utils.data.random_split(full_dataset, [train_size, valid_size])\n",
    "\n",
    "    # Dataset using the \"testing\" folder\n",
    "    testing_set = loader(path / \"testing\")\n",
    "    \n",
    "    return training_set, testing_set, validation_set\n",
    "\n",
    "\n",
    "loader = pic_loader(pic_transform=pic_to_column, label_transform=one_hot)\n",
    "training_set, testing_set, validation_set = load_mnist(loader, train_proportion=0.8)\n",
    "print(len(training_set), len(testing_set), len(validation_set))\n",
    "\n",
    "training_set = DataLoader(training_set, batch_size=30, shuffle=True)\n",
    "testing_set = DataLoader(testing_set, batch_size=30, shuffle=True)\n",
    "validation_set = DataLoader(validation_set, batch_size=30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1713,
   "id": "11ef64f0-7981-4fd7-869e-2903a9d77a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def graph_updater():\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1) \n",
    "\n",
    "    def add_datapoint(y):\n",
    "        xs, ys = [], []\n",
    "        if ax.lines:\n",
    "            xs = ax.lines[0].get_xdata()\n",
    "            ys = ax.lines[0].get_ydata()\n",
    "\n",
    "        prev_x = xs[-1] if len(xs) > 0 else 0        \n",
    "\n",
    "        ax.cla()\n",
    "        ax.plot(np.append(xs, prev_x + 1), np.append(ys, y))\n",
    "        \n",
    "        #ax.set_xlim(0, prev_x + 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        \n",
    "        display(fig)\n",
    "\n",
    "        clear_output(wait = True)\n",
    "    \n",
    "    return add_datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1707,
   "id": "cc7bf7b2-9df7-48ae-bea8-27948128adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct(expected, output):\n",
    "    return int(torch.argmax(expected) == torch.argmax(output))\n",
    "       \n",
    "\n",
    "def cost(expected, output):\n",
    "    return torch.sum((expected - output)**2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1708,
   "id": "56a6571d-afca-4811-90c8-7fe7212d9587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_layer_grads(grads):\n",
    "    return [torch.stack(i).mean(0) for i in zip(*grads)]\n",
    "    \n",
    "\n",
    "def merge_grads(grads):\n",
    "    return [merge_layer_grads(l) for l in zip(*grads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1705,
   "id": "9c566f3a-ca52-4386-a55c-cf29e23e96cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2(a, b):\n",
    "    return torch.sum((a - b)**2) / 2\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, layers, lr=0.001, nonlinearity=torch.nn.Sigmoid(), deriv=lambda x: x * (1 - x), cost_func=l2):\n",
    "        self.activation = nonlinearity\n",
    "        self.deriv = deriv\n",
    "        self.cost_func = cost_func\n",
    "        self.lr = lr\n",
    "        self.w = [torch.rand(n_out, n_in) / torch.sqrt(tensor(n_in)) for n_in, n_out in zip(layers, layers[1:])]\n",
    "        self.b = [torch.rand(n_out, 1) for n_out in layers[1:]]\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        a = inputs\n",
    "        activations = [a]\n",
    "        for w, b in zip(self.w, self.b):\n",
    "            a = self.activation(w @ a + b)\n",
    "            activations.append(a)\n",
    "        return activations\n",
    "         \n",
    "    def step(self, inputs):\n",
    "        return self.forward(inputs)[-1]\n",
    "    \n",
    "    def gradient(self, activations, expected):\n",
    "        layer_gradients = []\n",
    "       \n",
    "        in_ = activations[-2]\n",
    "        out = activations[-1]\n",
    "\n",
    "        nabla_C = out - expected\n",
    "        sigma_L = self.deriv(out)\n",
    "        delta_L = nabla_C * self.deriv(out)\n",
    "\n",
    "        prev_delta = delta_L\n",
    "        \n",
    "        dw = prev_delta @ torch.transpose(in_, 0, 1) \n",
    "        db = prev_delta \n",
    "        layer_gradients.append([dw, db])\n",
    "        \n",
    "        for l in range(len(self.w) - 2, -1, -1):\n",
    "            in_ = activations[l]\n",
    "            out = activations[l+1]\n",
    "            \n",
    "            delta_l = (torch.transpose(self.w[l+1], 0, 1) @ prev_delta) * self.deriv(out)\n",
    "            prev_delta = delta_l\n",
    "            \n",
    "            dw = delta_l @ torch.transpose(in_, 0, 1)\n",
    "            db = delta_l\n",
    "            \n",
    "            layer_gradients.append([dw, db])\n",
    "        \n",
    "        return list(reversed(layer_gradients))\n",
    "    \n",
    "    def update(self, gradient, lr):\n",
    "        for i, (w, b) in enumerate(gradient):\n",
    "            self.w[i] -= lr * w\n",
    "            self.b[i] -= lr * b\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1737,
   "id": "221de779-4e9d-46a6-a6f5-ac521f3d8848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(network, dataset, lr):\n",
    "    accuracy = []\n",
    "    costs = []\n",
    "    \n",
    "    for batch in iter(dataset):\n",
    "        grads = []\n",
    "        for xs, expected in zip(*batch):\n",
    "            activations = network.forward(xs)\n",
    "            output = activations[-1]\n",
    "            grad = network.gradient(activations, expected)\n",
    "            grads.append(grad)\n",
    "            accuracy.append(is_correct(expected, output))\n",
    "            costs.append(cost(expected, output))\n",
    "         \n",
    "        grad = merge_grads(grads)\n",
    "        network.update(grad, lr)\n",
    "\n",
    "    return tensor(accuracy).float().mean(), torch.stack(costs).mean()\n",
    "\n",
    "\n",
    "def train(network, dataset, epochs, lr, show_progress=True):\n",
    "    if show_progress:\n",
    "        add_datapoint = graph_updater()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = datetime.now()\n",
    "        \n",
    "        avg_accuracy, avg_cost = run_epoch(network, dataset, lr)\n",
    "        \n",
    "        if show_progress and (not epoch % 1):\n",
    "            print(f'epoch {epoch}: accuracy={round(avg_accuracy.item(), 3)}, cost={round(avg_cost.item(), 3)}, time: {datetime.now() - start}')\n",
    "            add_datapoint(avg_accuracy)\n",
    "    \n",
    "    return avg_accuracy, avg_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1738,
   "id": "2485578e-c56f-4263-b90d-da629ccb9440",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Network((28*28, 50, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77eb00b-a945-489f-a4a9-d17627ffee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(n, training_set, 5, lr=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d381a6a-ce92-49cd-8b86-f41eaf796dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
